{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1> MJRL training </h1>\n",
    "MJRL Algorithms: TRPO - MBAC - PPO - NPG - DAPG <br>\n",
    "source: https://github.com/aravindr93/mjrl/tree/master/mjrl/algos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MyoSuite:> Registering Myo Envs\n",
      "\u001b[36m    MyoSuite: A contact-rich simulation suite for musculoskeletal motor control\n",
      "        Vittorio Caggiano, Huawei Wang, Guillaume Durandau, Massimo Sartori, Vikash Kumar\n",
      "        L4DC-2019 | https://sites.google.com/view/myosuite\n",
      "    \u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([-2.2856e-02,  1.1130e-02, -8.2680e-02,  1.0125e-01, -4.9400e-02,\n",
       "        1.6578e-01,  1.1868e-01, -1.9320e-01, -1.9648e-01,  3.8760e-02,\n",
       "        1.6806e-01,  1.7281e-01, -2.5407e-01, -1.0998e-01,  1.4748e+00,\n",
       "        1.2882e+00,  1.0647e-01, -2.7489e-01,  3.3200e-01,  4.1140e-01,\n",
       "       -1.7716e-01, -2.6182e-01,  1.8852e-01,  1.7017e-01,  4.4773e-01,\n",
       "        2.6707e-01,  2.8278e-01, -1.0472e-02,  1.6854e-02,  7.0198e-03,\n",
       "        9.1390e-02, -6.5450e-02,  2.4350e-01,  3.3776e-01,  2.3565e-01,\n",
       "       -1.0184e-01,  6.0707e-04,  3.1420e-02, -2.0000e-01,  0.0000e+00,\n",
       "       -2.0000e-02,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
       "        0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
       "        0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
       "        0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
       "        0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
       "        0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
       "        0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
       "        0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
       "        0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
       "        0.0000e+00,  0.0000e+00,  0.0000e+00, -3.5000e-01, -3.0000e-01,\n",
       "        1.0700e+00,  1.1091e-01,  6.0471e-02, -1.7668e-02,  0.0000e+00,\n",
       "        0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
       "        0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
       "        0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
       "        0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
       "        0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
       "        0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
       "        0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
       "        0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
       "        0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
       "        0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
       "        0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
       "        0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
       "        0.0000e+00,  0.0000e+00])"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import gym\n",
    "from mjrl.utils.gym_env import GymEnv\n",
    "from mjrl.policies.gaussian_mlp import MLP\n",
    "from mjrl.baselines.mlp_baseline import MLPBaseline\n",
    "from mjrl.algos.ppo_clip import PPO\n",
    "from mjrl.algos.npg_cg import NPG\n",
    "from mjrl.utils.train_agent import train_agent\n",
    "import myosuite\n",
    "\n",
    "# Create the environment\n",
    "# Find tasks in: \\envs\\myo\\myobase or \\envs\\myo\\myochallenge\n",
    "env = gym.make('CenterReachOut-v0')\n",
    "env.reset()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1> Hyperparameter tuning </h1>\n",
    "Still working on it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import ParameterSampler\n",
    "\n",
    "param_grid = {\n",
    "    'policy_size': [(256, 256), (128, 128), (64, 64)],\n",
    "    'rl_step_size': np.logspace(-4, 0, num=10),\n",
    "    'learnrate': np.logspace(-4, 0, num=10),\n",
    "    'entcoeff': np.logspace(-4, 0, num=10),\n",
    "    'batchsize': [16, 32, 64, 128],\n",
    "    'num_epoch': [5, 10, 20],\n",
    "    'vf_hidden_size': [(256, 256), (128, 128), (64, 64)],\n",
    "    'regcoef': np.logspace(-4, 0, num=10),\n",
    "    'gamma': np.linspace(0.9, 0.999, num=10),\n",
    "    'gae_lambda': np.linspace(0.9, 1.0, num=10)\n",
    "}\n",
    "\n",
    "n_iter_search = 50  \n",
    "\n",
    "random_search = list(ParameterSampler(param_grid, n_iter=n_iter_search, random_state=123))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Policy hyperparameters\n",
    "policy_size = (256, 256)  # Size of the policy network\n",
    "seed = 123  # Random seed used for reproducibility\n",
    "rl_step_size = 0.1\n",
    "learnrate = 0.025\n",
    "entcoeff = 0.01\n",
    "batchsize = 32\n",
    "num_epoch = 10\n",
    "\n",
    "#Value Function hyperparameters\n",
    "vf_hidden_size = (256, 256) # Value Function Network size\n",
    "seed = 123  # Random seed used for reproducibility\n",
    "rl_step_size = 0.1\n",
    "learnrate = 0.025\n",
    "entcoeff = 0.01\n",
    "batchsize = 32\n",
    "num_epoch = 10\n",
    "regcoef = 1e-3\n",
    "\n",
    "#Training hyperparameters\n",
    "iterations = 1000\n",
    "gamma = 0.995\n",
    "gae_lambda = 0.97\n",
    "\n",
    "\n",
    "# Wrap the environment\n",
    "e = GymEnv(env)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<H1>Set Policies </h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize policy and baseline\n",
    "policy = MLP(e.spec, hidden_sizes=policy_size, seed=seed, init_log_std=-0.25, min_log_std=-1.0)\n",
    "baseline = MLPBaseline(e.spec, reg_coef=regcoef, batch_size=batchsize , hidden_sizes=vf_hidden_size, epochs=num_epoch, learn_rate=learnrate)\n",
    "\n",
    "# Initialize NPG/PPO agent\n",
    "agent = NPG(e, policy, baseline, normalized_step_size=rl_step_size, seed=seed, save_logs=True,ent_coeff=entcoeff ,tensorboard_log=\"./ppo_objhold_tensorboard/\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1> Start Training </h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========================================\n",
      "Starting policy learning\n",
      "========================================\n",
      "......................................................................................\n",
      "ITERATION : 0 \n",
      "Performing evaluation rollouts ........\n",
      "Iter | Stoc Pol | Mean Pol | Best (Stoc) \n",
      "\n",
      "[ Fri May 17 15:33:54 2024 ]    0 -4226.35 -2994.37 -100000000.00 \n",
      "------------------  -------------\n",
      "VF_error_after          0.017988\n",
      "VF_error_before         0.999976\n",
      "alpha                   0.420992\n",
      "delta                   0.1\n",
      "env_samples          8259\n",
      "eval_score          -2994.37\n",
      "eval_success            0\n",
      "kl_dist                 0.0496465\n",
      "num_samples          8259\n",
      "rollout_success         0\n",
      "running_score       -4226.35\n",
      "rwd_dense             -42.2635\n",
      "rwd_sparse             -0.401014\n",
      "stoc_pol_max           19.5302\n",
      "stoc_pol_mean       -4226.35\n",
      "stoc_pol_min        -5050.48\n",
      "stoc_pol_std         1736.28\n",
      "success_percentage      0\n",
      "surr_improvement        0.276954\n",
      "time_VF                 5.30057\n",
      "time_npg                2.10066\n",
      "time_sampling          19.6421\n",
      "time_vpg                0.342273\n",
      "------------------  -------------\n",
      "......................................................................................\n",
      "ITERATION : 1 \n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[5], line 6\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m========================================\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m      5\u001b[0m \u001b[38;5;66;03m# Train the agent\u001b[39;00m\n\u001b[1;32m----> 6\u001b[0m \u001b[43mtrain_agent\u001b[49m\u001b[43m(\u001b[49m\u001b[43mjob_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m.\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m      7\u001b[0m \u001b[43m            \u001b[49m\u001b[43magent\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43magent\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m      8\u001b[0m \u001b[43m            \u001b[49m\u001b[43mseed\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mseed\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m      9\u001b[0m \u001b[43m            \u001b[49m\u001b[43mniter\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m10000\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m     10\u001b[0m \u001b[43m            \u001b[49m\u001b[43mgamma\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgamma\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     11\u001b[0m \u001b[43m            \u001b[49m\u001b[43mgae_lambda\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgae_lambda\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     12\u001b[0m \u001b[43m            \u001b[49m\u001b[43msample_mode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtrajectories\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m     13\u001b[0m \u001b[43m            \u001b[49m\u001b[43mnum_traj\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m96\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m     14\u001b[0m \u001b[43m            \u001b[49m\u001b[43mnum_samples\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m     15\u001b[0m \u001b[43m            \u001b[49m\u001b[43msave_freq\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m100\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m     16\u001b[0m \u001b[43m            \u001b[49m\u001b[43mevaluation_rollouts\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     18\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m========================================\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     19\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mJob Finished.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\Elyas\\anaconda3\\envs\\myosuite\\lib\\site-packages\\mjrl\\utils\\train_agent.py:107\u001b[0m, in \u001b[0;36mtrain_agent\u001b[1;34m(job_name, agent, seed, niter, gamma, gae_lambda, num_cpu, sample_mode, num_traj, num_samples, save_freq, evaluation_rollouts, plot_keys)\u001b[0m\n\u001b[0;32m    105\u001b[0m N \u001b[38;5;241m=\u001b[39m num_traj \u001b[38;5;28;01mif\u001b[39;00m sample_mode \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtrajectories\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m num_samples\n\u001b[0;32m    106\u001b[0m args \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mdict\u001b[39m(N\u001b[38;5;241m=\u001b[39mN, sample_mode\u001b[38;5;241m=\u001b[39msample_mode, gamma\u001b[38;5;241m=\u001b[39mgamma, gae_lambda\u001b[38;5;241m=\u001b[39mgae_lambda, num_cpu\u001b[38;5;241m=\u001b[39mnum_cpu)\n\u001b[1;32m--> 107\u001b[0m stats \u001b[38;5;241m=\u001b[39m \u001b[43magent\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_step\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    108\u001b[0m train_curve[i] \u001b[38;5;241m=\u001b[39m stats[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m    109\u001b[0m \u001b[38;5;66;03m# log total number of samples so far for convinience\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Elyas\\anaconda3\\envs\\myosuite\\lib\\site-packages\\mjrl\\algos\\batch_reinforce.py:82\u001b[0m, in \u001b[0;36mBatchREINFORCE.train_step\u001b[1;34m(self, N, env, sample_mode, horizon, gamma, gae_lambda, num_cpu, env_kwargs)\u001b[0m\n\u001b[0;32m     79\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m sample_mode \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtrajectories\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[0;32m     80\u001b[0m     input_dict \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mdict\u001b[39m(num_traj\u001b[38;5;241m=\u001b[39mN, env\u001b[38;5;241m=\u001b[39menv, policy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpolicy, horizon\u001b[38;5;241m=\u001b[39mhorizon,\n\u001b[0;32m     81\u001b[0m                       base_seed\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mseed, num_cpu\u001b[38;5;241m=\u001b[39mnum_cpu, env_kwargs\u001b[38;5;241m=\u001b[39menv_kwargs)\n\u001b[1;32m---> 82\u001b[0m     paths \u001b[38;5;241m=\u001b[39m \u001b[43mtrajectory_sampler\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msample_paths\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43minput_dict\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     83\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m sample_mode \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124msamples\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[0;32m     84\u001b[0m     input_dict \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mdict\u001b[39m(num_samples\u001b[38;5;241m=\u001b[39mN, env\u001b[38;5;241m=\u001b[39menv, policy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpolicy, horizon\u001b[38;5;241m=\u001b[39mhorizon,\n\u001b[0;32m     85\u001b[0m                       base_seed\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mseed, num_cpu\u001b[38;5;241m=\u001b[39mnum_cpu, env_kwargs\u001b[38;5;241m=\u001b[39menv_kwargs)\n",
      "File \u001b[1;32mc:\\Users\\Elyas\\anaconda3\\envs\\myosuite\\lib\\site-packages\\mjrl\\samplers\\core.py:124\u001b[0m, in \u001b[0;36msample_paths\u001b[1;34m(num_traj, env, policy, eval_mode, horizon, base_seed, num_cpu, max_process_time, max_timeouts, suppress_print, env_kwargs)\u001b[0m\n\u001b[0;32m    120\u001b[0m     input_dict \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mdict\u001b[39m(num_traj\u001b[38;5;241m=\u001b[39mnum_traj, env\u001b[38;5;241m=\u001b[39menv, policy\u001b[38;5;241m=\u001b[39mpolicy,\n\u001b[0;32m    121\u001b[0m                       eval_mode\u001b[38;5;241m=\u001b[39meval_mode, horizon\u001b[38;5;241m=\u001b[39mhorizon, base_seed\u001b[38;5;241m=\u001b[39mbase_seed,\n\u001b[0;32m    122\u001b[0m                       env_kwargs\u001b[38;5;241m=\u001b[39menv_kwargs)\n\u001b[0;32m    123\u001b[0m     \u001b[38;5;66;03m# dont invoke multiprocessing if not necessary\u001b[39;00m\n\u001b[1;32m--> 124\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mdo_rollout\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43minput_dict\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    126\u001b[0m \u001b[38;5;66;03m# do multiprocessing otherwise\u001b[39;00m\n\u001b[0;32m    127\u001b[0m paths_per_cpu \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mint\u001b[39m(np\u001b[38;5;241m.\u001b[39mceil(num_traj\u001b[38;5;241m/\u001b[39mnum_cpu))\n",
      "File \u001b[1;32mc:\\Users\\Elyas\\anaconda3\\envs\\myosuite\\lib\\site-packages\\mjrl\\samplers\\core.py:71\u001b[0m, in \u001b[0;36mdo_rollout\u001b[1;34m(num_traj, env, policy, eval_mode, horizon, base_seed, env_kwargs)\u001b[0m\n\u001b[0;32m     68\u001b[0m t \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[0;32m     70\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m t \u001b[38;5;241m<\u001b[39m horizon \u001b[38;5;129;01mand\u001b[39;00m done \u001b[38;5;241m!=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[1;32m---> 71\u001b[0m     a, agent_info \u001b[38;5;241m=\u001b[39m \u001b[43mpolicy\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_action\u001b[49m\u001b[43m(\u001b[49m\u001b[43mo\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     72\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m eval_mode:\n\u001b[0;32m     73\u001b[0m         a \u001b[38;5;241m=\u001b[39m agent_info[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mevaluation\u001b[39m\u001b[38;5;124m'\u001b[39m]\n",
      "File \u001b[1;32mc:\\Users\\Elyas\\anaconda3\\envs\\myosuite\\lib\\site-packages\\mjrl\\policies\\gaussian_mlp.py:94\u001b[0m, in \u001b[0;36mMLP.get_action\u001b[1;34m(self, observation)\u001b[0m\n\u001b[0;32m     92\u001b[0m o \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mfloat32(observation\u001b[38;5;241m.\u001b[39mreshape(\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m))\n\u001b[0;32m     93\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobs_var\u001b[38;5;241m.\u001b[39mdata \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mfrom_numpy(o)\n\u001b[1;32m---> 94\u001b[0m mean \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mobs_var\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mdata\u001b[38;5;241m.\u001b[39mnumpy()\u001b[38;5;241m.\u001b[39mravel()\n\u001b[0;32m     95\u001b[0m noise \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mexp(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlog_std_val) \u001b[38;5;241m*\u001b[39m np\u001b[38;5;241m.\u001b[39mrandom\u001b[38;5;241m.\u001b[39mrandn(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mm)\n\u001b[0;32m     96\u001b[0m action \u001b[38;5;241m=\u001b[39m mean \u001b[38;5;241m+\u001b[39m noise\n",
      "File \u001b[1;32mc:\\Users\\Elyas\\anaconda3\\envs\\myosuite\\lib\\site-packages\\torch\\nn\\modules\\module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Elyas\\anaconda3\\envs\\myosuite\\lib\\site-packages\\torch\\nn\\modules\\module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Elyas\\anaconda3\\envs\\myosuite\\lib\\site-packages\\mjrl\\utils\\fc_network.py:48\u001b[0m, in \u001b[0;36mFCNetwork.forward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m     46\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m     47\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m\n\u001b[1;32m---> 48\u001b[0m out \u001b[38;5;241m=\u001b[39m (\u001b[43mout\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43min_shift\u001b[49m)\u001b[38;5;241m/\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39min_scale \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1e-8\u001b[39m)\n\u001b[0;32m     49\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfc_layers)\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m):\n\u001b[0;32m     50\u001b[0m     out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfc_layers[i](out)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "print(\"========================================\")\n",
    "print(\"Starting policy learning\")\n",
    "print(\"========================================\")\n",
    "\n",
    "# Train the agent\n",
    "train_agent(job_name='.',\n",
    "            agent=agent,\n",
    "            seed=seed,\n",
    "            niter=10000,\n",
    "            gamma=gamma,\n",
    "            gae_lambda=gae_lambda,\n",
    "            sample_mode=\"trajectories\",\n",
    "            num_traj=96,\n",
    "            num_samples=0,\n",
    "            save_freq=100,\n",
    "            evaluation_rollouts=10)\n",
    "\n",
    "print(\"========================================\")\n",
    "print(\"Job Finished.\")\n",
    "print(\"========================================\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1> Logging hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'myoarmreach#9/readme.txt'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[6], line 26\u001b[0m\n\u001b[0;32m      2\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\"\"\u001b[39m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;124m# Policy hyperparameters\u001b[39m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;124mpolicy_size = \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpolicy_size\u001b[38;5;132;01m}\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     22\u001b[0m \n\u001b[0;32m     23\u001b[0m \u001b[38;5;124m\"\"\"\u001b[39m\n\u001b[0;32m     25\u001b[0m \u001b[38;5;66;03m# Write data to the file\u001b[39;00m\n\u001b[1;32m---> 26\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmyoarmreach#9/readme.txt\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mw\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m file: \u001b[38;5;66;03m#Change the folder name \u001b[39;00m\n\u001b[0;32m     27\u001b[0m     file\u001b[38;5;241m.\u001b[39mwrite(data)\n",
      "File \u001b[1;32mc:\\Users\\Elyas\\anaconda3\\envs\\myosuite\\lib\\site-packages\\IPython\\core\\interactiveshell.py:284\u001b[0m, in \u001b[0;36m_modified_open\u001b[1;34m(file, *args, **kwargs)\u001b[0m\n\u001b[0;32m    277\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m file \u001b[38;5;129;01min\u001b[39;00m {\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m2\u001b[39m}:\n\u001b[0;32m    278\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    279\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIPython won\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt let you open fd=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfile\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m by default \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    280\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mas it is likely to crash IPython. If you know what you are doing, \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    281\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124myou can use builtins\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m open.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    282\u001b[0m     )\n\u001b[1;32m--> 284\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mio_open\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'myoarmreach#9/readme.txt'"
     ]
    }
   ],
   "source": [
    "# Data to be written into the file\n",
    "data = f\"\"\"\n",
    "# Policy hyperparameters\n",
    "policy_size = {policy_size}\n",
    "seed = {seed}\n",
    "rl_step_size = {rl_step_size}\n",
    "learnrate = {learnrate}\n",
    "entcoeff = {entcoeff}\n",
    "batchsize = {batchsize}\n",
    "num_epoch = {num_epoch}\n",
    "\n",
    "# Value Function hyperparameters\n",
    "vf_hidden_size = {vf_hidden_size}\n",
    "seed = {seed}\n",
    "rl_step_size = {rl_step_size}\n",
    "learnrate = {learnrate}\n",
    "entcoeff = {entcoeff}\n",
    "batchsize = {batchsize}\n",
    "num_epoch = {num_epoch}\n",
    "regcoef = {regcoef}\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "# Write data to the file\n",
    "with open(\"myoarmreach#9/readme.txt\", \"w\") as file: #Change the folder name \n",
    "    file.write(data)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

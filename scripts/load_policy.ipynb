{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MyoSuite:> Registering Myo Envs\n"
     ]
    }
   ],
   "source": [
    "import myosuite\n",
    "import gym\n",
    "import skvideo.io\n",
    "import numpy as np\n",
    "import os\n",
    "import imageio\n",
    "import tqdm\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Display Settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import HTML\n",
    "from base64 import b64encode\n",
    "\n",
    "def show_video(video_path, video_width = 400):\n",
    "\n",
    "  video_file = open(video_path, \"r+b\").read()\n",
    "\n",
    "  video_url = f\"data:video/mp4;base64,{b64encode(video_file).decode()}\"\n",
    "  return HTML(f\"\"\"<video autoplay width={video_width} controls><source src=\"{video_url}\"></video>\"\"\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2> Load Policy </h2>\n",
    "<p>This code specifically uses unpickling to get the policy (mjrl). </p>\n",
    "<p>Note: The policy is /policies/gaussian_mlp.py </p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[5], line 19\u001b[0m\n\u001b[0;32m     17\u001b[0m obs \u001b[38;5;241m=\u001b[39m env\u001b[38;5;241m.\u001b[39mreset()\n\u001b[0;32m     18\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m done:\n\u001b[1;32m---> 19\u001b[0m     o \u001b[38;5;241m=\u001b[39m \u001b[43menv\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_obs\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     20\u001b[0m     \u001b[38;5;66;03m# get the next action from the policy\u001b[39;00m\n\u001b[0;32m     21\u001b[0m     action, _ \u001b[38;5;241m=\u001b[39m pi\u001b[38;5;241m.\u001b[39mget_action(o)\n",
      "File \u001b[1;32mc:\\Users\\Elyas\\anaconda3\\envs\\myosuite\\lib\\site-packages\\myosuite\\envs\\env_base.py:302\u001b[0m, in \u001b[0;36mMujocoEnv.get_obs\u001b[1;34m(self, update_proprioception, update_exteroception)\u001b[0m\n\u001b[0;32m    299\u001b[0m sen \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrobot\u001b[38;5;241m.\u001b[39mget_sensors()\n\u001b[0;32m    301\u001b[0m \u001b[38;5;66;03m# reconstruct (partially) observed-sim using (noisy) sensor data\u001b[39;00m\n\u001b[1;32m--> 302\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrobot\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msensor2sim\u001b[49m\u001b[43m(\u001b[49m\u001b[43msen\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msim_obsd\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    304\u001b[0m \u001b[38;5;66;03m# get obs_dict using the observed information\u001b[39;00m\n\u001b[0;32m    305\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobs_dict \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_obs_dict(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msim_obsd)\n",
      "File \u001b[1;32mc:\\Users\\Elyas\\anaconda3\\envs\\myosuite\\lib\\site-packages\\myosuite\\robot\\robot.py:484\u001b[0m, in \u001b[0;36mRobot.sensor2sim\u001b[1;34m(self, sensor, sim)\u001b[0m\n\u001b[0;32m    482\u001b[0m             data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(sim\u001b[38;5;241m.\u001b[39mdata, s_val[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdata_type\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[0;32m    483\u001b[0m             data[s_val[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdata_id\u001b[39m\u001b[38;5;124m\"\u001b[39m]] \u001b[38;5;241m=\u001b[39m sensor[name][s_id]\n\u001b[1;32m--> 484\u001b[0m \u001b[43msim\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mforward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Elyas\\anaconda3\\envs\\myosuite\\lib\\site-packages\\myosuite\\physics\\sim_scene.py:106\u001b[0m, in \u001b[0;36mSimScene.forward\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    104\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    105\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Run the simulation forward\"\"\"\u001b[39;00m\n\u001b[1;32m--> 106\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msim\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mforward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    107\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrenderer\u001b[38;5;241m.\u001b[39mrefresh_window()\n",
      "File \u001b[1;32mc:\\Users\\Elyas\\anaconda3\\envs\\myosuite\\lib\\site-packages\\dm_control\\mujoco\\engine.py:321\u001b[0m, in \u001b[0;36mPhysics.forward\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    315\u001b[0m \u001b[38;5;66;03m# Note: `mj_forward` differs from `mj_step1` in that it also recomputes\u001b[39;00m\n\u001b[0;32m    316\u001b[0m \u001b[38;5;66;03m# quantities that depend on acceleration (and therefore on the state of the\u001b[39;00m\n\u001b[0;32m    317\u001b[0m \u001b[38;5;66;03m# controls). For example `mj_forward` updates accelerometer and gyro\u001b[39;00m\n\u001b[0;32m    318\u001b[0m \u001b[38;5;66;03m# readings, whereas `mj_step1` does not.\u001b[39;00m\n\u001b[0;32m    319\u001b[0m \u001b[38;5;66;03m# http://www.mujoco.org/book/programming.html#siForward\u001b[39;00m\n\u001b[0;32m    320\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcheck_invalid_state():\n\u001b[1;32m--> 321\u001b[0m   \u001b[43mmujoco\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmj_forward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mptr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdata\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mptr\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "env = gym.make('CenterReachOut-v0')\n",
    "policy = \"../training/iterations/best_policy.pickle\" #Change the folder to the policy location\n",
    "\n",
    "import pickle\n",
    "# load policy\n",
    "pi = pickle.load(open(policy, 'rb'))\n",
    "\n",
    "#pi is the trained policy neural network\n",
    "\n",
    "all_rewards = []\n",
    "\n",
    "frames = []\n",
    "for _ in range(100): # 20 random targets\n",
    "  env.reset()\n",
    "  ep_rewards = []\n",
    "  done = False\n",
    "  obs = env.reset()\n",
    "  while not done:\n",
    "      o = env.get_obs()\n",
    "      # get the next action from the policy\n",
    "      action, _ = pi.get_action(o)\n",
    "      # take an action based on the current observation\n",
    "      obs, reward, done, info = env.step(action)\n",
    "      ep_rewards.append(reward)\n",
    "  all_rewards.append(np.sum(ep_rewards))\n",
    "\n",
    "print(f\"Average reward: {np.mean(all_rewards) / 100} over 20 episodes\")\n",
    "\n",
    "\n",
    "env.close()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Camera Id's:\n",
    "// 0 - Side facing\n",
    "// 1 - Front facing\n",
    "// 2 - Above facing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'mjrl.policies.gaussian_mlp.MLP'>\n",
      "episode  0 :\n",
      "[-0.2391 -0.2395  1.0523]\n",
      "episode  1 :\n",
      "[-0.2391 -0.2395  1.0523]\n",
      "episode  2 :\n",
      "[-0.2391 -0.2395  1.0523]\n",
      "episode  3 :\n",
      "[-0.2391 -0.2395  1.0523]\n",
      "episode  4 :\n",
      "[-0.2391 -0.2395  1.0523]\n",
      "episode  5 :\n",
      "[-0.2391 -0.2395  1.0523]\n",
      "episode  6 :\n",
      "[-0.2391 -0.2395  1.0523]\n",
      "episode  7 :\n",
      "[-0.2391 -0.2395  1.0523]\n",
      "episode  8 :\n",
      "[-0.2391 -0.2395  1.0523]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[4], line 16\u001b[0m\n\u001b[0;32m     14\u001b[0m obs \u001b[38;5;241m=\u001b[39m env\u001b[38;5;241m.\u001b[39mreset()\n\u001b[0;32m     15\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m done:\n\u001b[1;32m---> 16\u001b[0m     frame \u001b[38;5;241m=\u001b[39m \u001b[43menv\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msim\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrenderer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrender_offscreen\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcamera_id\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m     17\u001b[0m \u001b[43m                      \u001b[49m\u001b[43mwidth\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m400\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m     18\u001b[0m \u001b[43m                      \u001b[49m\u001b[43mheight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m400\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     19\u001b[0m     frames\u001b[38;5;241m.\u001b[39mappend(frame)\n\u001b[0;32m     20\u001b[0m     o \u001b[38;5;241m=\u001b[39m env\u001b[38;5;241m.\u001b[39mget_obs()\n",
      "File \u001b[1;32mc:\\Users\\Elyas\\anaconda3\\envs\\myosuite\\lib\\site-packages\\myosuite\\renderer\\mj_renderer.py:112\u001b[0m, in \u001b[0;36mMJRenderer.render_offscreen\u001b[1;34m(self, width, height, rgb, depth, segmentation, camera_id, device_id)\u001b[0m\n\u001b[0;32m    110\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m rgb:\n\u001b[0;32m    111\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_renderer\u001b[38;5;241m.\u001b[39mupdate_scene(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sim\u001b[38;5;241m.\u001b[39mdata\u001b[38;5;241m.\u001b[39mptr, camera\u001b[38;5;241m=\u001b[39mcamera_id, scene_option\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_scene_option)\n\u001b[1;32m--> 112\u001b[0m     rgb_arr \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_renderer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrender\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    113\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m depth:\n\u001b[0;32m    114\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_renderer\u001b[38;5;241m.\u001b[39menable_depth_rendering()\n",
      "File \u001b[1;32mc:\\Users\\Elyas\\anaconda3\\envs\\myosuite\\lib\\site-packages\\mujoco\\renderer.py:207\u001b[0m, in \u001b[0;36mRenderer.render\u001b[1;34m(self, out)\u001b[0m\n\u001b[0;32m    205\u001b[0m   np\u001b[38;5;241m.\u001b[39mcopyto(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_scene\u001b[38;5;241m.\u001b[39mflags, original_flags)\n\u001b[0;32m    206\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 207\u001b[0m   \u001b[43m_render\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmjr_readPixels\u001b[49m\u001b[43m(\u001b[49m\u001b[43mout\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_rect\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_mjr_context\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    209\u001b[0m out[:] \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mflipud(out)\n\u001b[0;32m    211\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m out\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Use sleep if you want to examine certain steps during the episodes\n",
    "from time import sleep\n",
    "\n",
    "print(type(pi))\n",
    "\n",
    "# Render trained policy\n",
    "frames = []\n",
    "for _ in range(20): # 5 random targets\n",
    "  env.reset()\n",
    "  print(\"episode \", _, \":\")\n",
    "  print(env.obs_dict['palm_pos'])\n",
    "  ep_rewards = []\n",
    "  done = False\n",
    "  obs = env.reset()\n",
    "  while not done:\n",
    "      frame = env.sim.renderer.render_offscreen(camera_id=1,\n",
    "                        width=400,\n",
    "                        height=400)\n",
    "      frames.append(frame)\n",
    "      o = env.get_obs()\n",
    "      # get the next action from the policy\n",
    "      action, _ = pi.get_action(o)\n",
    "      #print(pi.show_activations())\n",
    "      #print(pi.get_neurons())\n",
    "      # take an action based on the current observation\n",
    "      obs, reward, done, info = env.step(action)\n",
    "\n",
    "env.close()\n",
    "\n",
    "os.makedirs('videos', exist_ok=True)\n",
    "video_path = 'videos/ff_policy.mp4'\n",
    "# make a local copy\n",
    "imageio.mimsave(video_path, frames, fps=30)\n",
    "show_video('videos/ff_policy.mp4')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myosuite",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1> MJRL training </h1>\n",
    "MJRL Algorithms: TRPO - MBAC - PPO - NPG - DAPG <br>\n",
    "source: https://github.com/aravindr93/mjrl/tree/master/mjrl/algos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MyoSuite:> Registering Myo Envs\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import gym\n",
    "from mjrl.utils.gym_env import GymEnv\n",
    "from mjrl.policies.gaussian_mlp import MLP\n",
    "from mjrl.policies.rnn import RNN\n",
    "from mjrl.baselines.mlp_baseline import MLPBaseline\n",
    "from mjrl.algos.ppo_clip import PPO\n",
    "from mjrl.algos.npg_cg import NPG\n",
    "from mjrl.utils.train_agent import train_agent\n",
    "import myosuite\n",
    "import torch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2> Setting up GPU Usage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m    MyoSuite: A contact-rich simulation suite for musculoskeletal motor control\n",
      "        Vittorio Caggiano, Huawei Wang, Guillaume Durandau, Massimo Sartori, Vikash Kumar\n",
      "        L4DC-2019 | https://sites.google.com/view/myosuite\n",
      "    \u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([-2.2856e-02,  1.1130e-02, -8.2680e-02,  1.0125e-01, -4.9400e-02,\n",
       "        1.6578e-01,  1.1868e-01, -1.9320e-01, -1.9648e-01,  3.8760e-02,\n",
       "        1.6806e-01,  1.7281e-01, -2.5407e-01, -1.0998e-01,  1.4748e+00,\n",
       "        1.2882e+00,  1.0647e-01, -2.7489e-01,  3.3200e-01,  4.1140e-01,\n",
       "       -1.7716e-01, -2.6182e-01,  1.8852e-01,  1.7017e-01,  4.4773e-01,\n",
       "        2.6707e-01,  2.8278e-01, -1.0472e-02,  1.6854e-02,  7.0198e-03,\n",
       "        9.1390e-02, -6.5450e-02,  2.4350e-01,  3.3776e-01,  2.3565e-01,\n",
       "       -1.0184e-01,  6.0707e-04,  3.1420e-02, -2.0000e-01,  0.0000e+00,\n",
       "       -2.0000e-02,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
       "        0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
       "        0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
       "        0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
       "        0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
       "        0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
       "        0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
       "        0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
       "        0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
       "        0.0000e+00,  0.0000e+00,  0.0000e+00, -2.3125e-01, -4.0094e-01,\n",
       "        1.0700e+00, -7.8400e-03,  1.6141e-01, -1.7668e-02,  0.0000e+00,\n",
       "        0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
       "        0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
       "        0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
       "        0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
       "        0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
       "        0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
       "        0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
       "        0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
       "        0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
       "        0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
       "        0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
       "        0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
       "        0.0000e+00,  0.0000e+00])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# Create the environment\n",
    "# Find tasks in: \\envs\\myo\\myobase or \\envs\\myo\\myochallenge\n",
    "env = gym.make('CenterReachOut-v0')\n",
    "env.reset()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1> Hyperparameter tuning </h1>\n",
    "Still working on it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import ParameterSampler\n",
    "\n",
    "param_grid = {\n",
    "    'policy_size': [(256, 256), (128, 128), (64, 64)],\n",
    "    'rl_step_size': np.logspace(-4, 0, num=10),\n",
    "    'learnrate': np.logspace(-4, 0, num=10),\n",
    "    'entcoeff': np.logspace(-4, 0, num=10),\n",
    "    'batchsize': [16, 32, 64, 128],\n",
    "    'num_epoch': [5, 10, 20],\n",
    "    'vf_hidden_size': [(256, 256), (128, 128), (64, 64)],\n",
    "    'regcoef': np.logspace(-4, 0, num=10),\n",
    "    'gamma': np.linspace(0.9, 0.999, num=10),\n",
    "    'gae_lambda': np.linspace(0.9, 1.0, num=10)\n",
    "}\n",
    "\n",
    "n_iter_search = 50  \n",
    "\n",
    "random_search = list(ParameterSampler(param_grid, n_iter=n_iter_search, random_state=123))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Policy hyperparameters\n",
    "policy_size = (256, 256)  # Size of the policy network\n",
    "seed = 123  # Random seed used for reproducibility\n",
    "rl_step_size = 0.1\n",
    "learnrate = 0.00025\n",
    "entcoeff = 0.01\n",
    "batchsize = 32\n",
    "num_epoch = 10\n",
    "\n",
    "#Value Function hyperparameters\n",
    "vf_hidden_size = (256, 256) # Value Function Network size\n",
    "seed = 123  # Random seed used for reproducibility\n",
    "rl_step_size = 0.1\n",
    "learnrate = 0.00025\n",
    "entcoeff = 0.01\n",
    "batchsize = 32\n",
    "num_epoch = 10\n",
    "regcoef = 1e-3\n",
    "\n",
    "#Training hyperparameters\n",
    "iterations = 1000\n",
    "gamma = 0.995\n",
    "gae_lambda = 0.97\n",
    "\n",
    "\n",
    "# Wrap the environment\n",
    "e = GymEnv(env)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<H1>Set Policies </h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2> For CenterReachOut: </h2>\n",
    "    - <b> The observation dimension </b> is: the sensory information (Time, joint Positions, Joint Velocities, Object Position, Palm Position etc... ) <br>\n",
    "    - <b> The action dimension </b> is the output of the Policy NN and represenents the 63 values of muscle actuator intensities\n",
    "\n",
    "<h2> Display Activations:</h2> \n",
    "    - When the code down below will run, it will automatically generate a tensorboard event that registers the Policy Network. \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "157\n",
      "63\n"
     ]
    }
   ],
   "source": [
    "# Initialize policy and baseline\n",
    "policy = MLP(e.spec, hidden_sizes=policy_size, seed=seed, init_log_std=0.25, min_log_std=1.0)\n",
    "baseline = MLPBaseline(e.spec, reg_coef=regcoef, batch_size=batchsize , hidden_sizes=vf_hidden_size, epochs=num_epoch, learn_rate=learnrate)\n",
    "\n",
    "\n",
    "print(e.observation_dim) #For CenterReachOut-v0: 157 \n",
    "print(e.action_dim) #For CenterReachOut-v0: 63 \n",
    "exit\n",
    "# Initialize NPG/PPO agent\n",
    "agent = NPG(e, policy, baseline, normalized_step_size=rl_step_size, seed=seed, save_logs=True,ent_coeff=entcoeff ,tensorboard_log=\"./ppo_objhold_tensorboard/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========================================\n",
      "Starting policy learning\n",
      "========================================\n",
      "......................................................................................\n",
      "ITERATION : 0 \n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "Dimension out of range (expected to be in range of [-1, 0], but got 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[7], line 6\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m========================================\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m      5\u001b[0m \u001b[38;5;66;03m# Train the agent\u001b[39;00m\n\u001b[1;32m----> 6\u001b[0m \u001b[43mtrain_agent\u001b[49m\u001b[43m(\u001b[49m\u001b[43mjob_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m.\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m      7\u001b[0m \u001b[43m            \u001b[49m\u001b[43magent\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43magent\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m      8\u001b[0m \u001b[43m            \u001b[49m\u001b[43mseed\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mseed\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m      9\u001b[0m \u001b[43m            \u001b[49m\u001b[43mniter\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m10000\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m     10\u001b[0m \u001b[43m            \u001b[49m\u001b[43mgamma\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgamma\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     11\u001b[0m \u001b[43m            \u001b[49m\u001b[43mgae_lambda\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgae_lambda\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     12\u001b[0m \u001b[43m            \u001b[49m\u001b[43msample_mode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtrajectories\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m     13\u001b[0m \u001b[43m            \u001b[49m\u001b[43mnum_traj\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m96\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m     14\u001b[0m \u001b[43m            \u001b[49m\u001b[43mnum_samples\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m     15\u001b[0m \u001b[43m            \u001b[49m\u001b[43msave_freq\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m50\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m     16\u001b[0m \u001b[43m            \u001b[49m\u001b[43mevaluation_rollouts\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     18\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m========================================\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     19\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mJob Finished.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\Elyas\\anaconda3\\envs\\myosuite\\lib\\site-packages\\mjrl\\utils\\train_agent.py:107\u001b[0m, in \u001b[0;36mtrain_agent\u001b[1;34m(job_name, agent, seed, niter, gamma, gae_lambda, num_cpu, sample_mode, num_traj, num_samples, save_freq, evaluation_rollouts, plot_keys)\u001b[0m\n\u001b[0;32m    105\u001b[0m N \u001b[38;5;241m=\u001b[39m num_traj \u001b[38;5;28;01mif\u001b[39;00m sample_mode \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtrajectories\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m num_samples\n\u001b[0;32m    106\u001b[0m args \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mdict\u001b[39m(N\u001b[38;5;241m=\u001b[39mN, sample_mode\u001b[38;5;241m=\u001b[39msample_mode, gamma\u001b[38;5;241m=\u001b[39mgamma, gae_lambda\u001b[38;5;241m=\u001b[39mgae_lambda, num_cpu\u001b[38;5;241m=\u001b[39mnum_cpu)\n\u001b[1;32m--> 107\u001b[0m stats \u001b[38;5;241m=\u001b[39m \u001b[43magent\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_step\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    108\u001b[0m train_curve[i] \u001b[38;5;241m=\u001b[39m stats[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m    109\u001b[0m \u001b[38;5;66;03m# log total number of samples so far for convinience\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Elyas\\anaconda3\\envs\\myosuite\\lib\\site-packages\\mjrl\\algos\\batch_reinforce.py:98\u001b[0m, in \u001b[0;36mBatchREINFORCE.train_step\u001b[1;34m(self, N, env, sample_mode, horizon, gamma, gae_lambda, num_cpu, env_kwargs)\u001b[0m\n\u001b[0;32m     96\u001b[0m process_samples\u001b[38;5;241m.\u001b[39mcompute_advantages(paths, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbaseline, gamma, gae_lambda)\n\u001b[0;32m     97\u001b[0m \u001b[38;5;66;03m# train from paths\u001b[39;00m\n\u001b[1;32m---> 98\u001b[0m eval_statistics \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_from_paths\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpaths\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     99\u001b[0m eval_statistics\u001b[38;5;241m.\u001b[39mappend(N)\n\u001b[0;32m    100\u001b[0m \u001b[38;5;66;03m# log number of samples\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Elyas\\anaconda3\\envs\\myosuite\\lib\\site-packages\\mjrl\\algos\\npg_cg.py:122\u001b[0m, in \u001b[0;36mNPG.train_from_paths\u001b[1;34m(self, paths)\u001b[0m\n\u001b[0;32m    119\u001b[0m ts \u001b[38;5;241m=\u001b[39m timer\u001b[38;5;241m.\u001b[39mtime()\n\u001b[0;32m    120\u001b[0m hvp \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbuild_Hvp_eval([observations, actions],\n\u001b[0;32m    121\u001b[0m                           regu_coef\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mFIM_invert_args[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdamping\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[1;32m--> 122\u001b[0m npg_grad \u001b[38;5;241m=\u001b[39m \u001b[43mcg_solve\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhvp\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvpg_grad\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx_0\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvpg_grad\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    123\u001b[0m \u001b[43m                    \u001b[49m\u001b[43mcg_iters\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mFIM_invert_args\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43miters\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    124\u001b[0m t_FIM \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m timer\u001b[38;5;241m.\u001b[39mtime() \u001b[38;5;241m-\u001b[39m ts\n\u001b[0;32m    126\u001b[0m \u001b[38;5;66;03m# Step size computation\u001b[39;00m\n\u001b[0;32m    127\u001b[0m \u001b[38;5;66;03m# --------------------------\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Elyas\\anaconda3\\envs\\myosuite\\lib\\site-packages\\mjrl\\utils\\cg_solve.py:10\u001b[0m, in \u001b[0;36mcg_solve\u001b[1;34m(f_Ax, b, x_0, cg_iters, residual_tol)\u001b[0m\n\u001b[0;32m      7\u001b[0m rdotr \u001b[38;5;241m=\u001b[39m r\u001b[38;5;241m.\u001b[39mdot(r)\n\u001b[0;32m      9\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(cg_iters):\n\u001b[1;32m---> 10\u001b[0m     z \u001b[38;5;241m=\u001b[39m \u001b[43mf_Ax\u001b[49m\u001b[43m(\u001b[49m\u001b[43mp\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     11\u001b[0m     v \u001b[38;5;241m=\u001b[39m rdotr \u001b[38;5;241m/\u001b[39m p\u001b[38;5;241m.\u001b[39mdot(z)\n\u001b[0;32m     12\u001b[0m     x \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m v \u001b[38;5;241m*\u001b[39m p\n",
      "File \u001b[1;32mc:\\Users\\Elyas\\anaconda3\\envs\\myosuite\\lib\\site-packages\\mjrl\\algos\\npg_cg.py:86\u001b[0m, in \u001b[0;36mNPG.build_Hvp_eval.<locals>.eval\u001b[1;34m(v)\u001b[0m\n\u001b[0;32m     84\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21meval\u001b[39m(v):\n\u001b[0;32m     85\u001b[0m     full_inp \u001b[38;5;241m=\u001b[39m inputs \u001b[38;5;241m+\u001b[39m [v] \u001b[38;5;241m+\u001b[39m [regu_coef]\n\u001b[1;32m---> 86\u001b[0m     Hvp \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mHVP\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mfull_inp\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     87\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m Hvp\n",
      "File \u001b[1;32mc:\\Users\\Elyas\\anaconda3\\envs\\myosuite\\lib\\site-packages\\mjrl\\algos\\npg_cg.py:75\u001b[0m, in \u001b[0;36mNPG.HVP\u001b[1;34m(self, observations, actions, vector, regu_coef)\u001b[0m\n\u001b[0;32m     73\u001b[0m old_dist_info \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpolicy\u001b[38;5;241m.\u001b[39mold_dist_info(obs, act)\n\u001b[0;32m     74\u001b[0m new_dist_info \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpolicy\u001b[38;5;241m.\u001b[39mnew_dist_info(obs, act)\n\u001b[1;32m---> 75\u001b[0m mean_kl \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpolicy\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmean_kl\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnew_dist_info\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mold_dist_info\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     76\u001b[0m grad_fo \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mautograd\u001b[38;5;241m.\u001b[39mgrad(mean_kl, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpolicy\u001b[38;5;241m.\u001b[39mtrainable_params, create_graph\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m     77\u001b[0m flat_grad \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mcat([g\u001b[38;5;241m.\u001b[39mcontiguous()\u001b[38;5;241m.\u001b[39mview(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m) \u001b[38;5;28;01mfor\u001b[39;00m g \u001b[38;5;129;01min\u001b[39;00m grad_fo])\n",
      "File \u001b[1;32mc:\\Users\\Elyas\\anaconda3\\envs\\myosuite\\lib\\site-packages\\mjrl\\policies\\gaussian_mlp.py:122\u001b[0m, in \u001b[0;36mMLP.mean_kl\u001b[1;34m(self, new_dist_info, old_dist_info)\u001b[0m\n\u001b[0;32m    120\u001b[0m Nr \u001b[38;5;241m=\u001b[39m (old_mean \u001b[38;5;241m-\u001b[39m new_mean) \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m \u001b[38;5;241m2\u001b[39m \u001b[38;5;241m+\u001b[39m old_std \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m \u001b[38;5;241m2\u001b[39m \u001b[38;5;241m-\u001b[39m new_std \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m \u001b[38;5;241m2\u001b[39m\n\u001b[0;32m    121\u001b[0m Dr \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m2\u001b[39m \u001b[38;5;241m*\u001b[39m new_std \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m \u001b[38;5;241m2\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1e-8\u001b[39m\n\u001b[1;32m--> 122\u001b[0m sample_kl \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msum\u001b[49m\u001b[43m(\u001b[49m\u001b[43mNr\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m/\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mDr\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mnew_log_std\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mold_log_std\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdim\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m    123\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mmean(sample_kl)\n",
      "\u001b[1;31mIndexError\u001b[0m: Dimension out of range (expected to be in range of [-1, 0], but got 1)"
     ]
    }
   ],
   "source": [
    "print(\"========================================\")\n",
    "print(\"Starting policy learning\")\n",
    "print(\"========================================\")\n",
    "\n",
    "# Train the agent\n",
    "train_agent(job_name='.',\n",
    "            agent=agent,\n",
    "            seed=seed,\n",
    "            niter=10000,\n",
    "            gamma=gamma,\n",
    "            gae_lambda=gae_lambda,\n",
    "            sample_mode=\"trajectories\",\n",
    "            num_traj=96,\n",
    "            num_samples=0,\n",
    "            save_freq=50,\n",
    "            evaluation_rollouts=10)\n",
    "\n",
    "print(\"========================================\")\n",
    "print(\"Job Finished.\")\n",
    "print(\"========================================\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1> Start Training </h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1> Logging hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data to be written into the file\n",
    "data = f\"\"\"\n",
    "# Policy hyperparameters\n",
    "policy_size = {policy_size}\n",
    "seed = {seed}\n",
    "rl_step_size = {rl_step_size}\n",
    "learnrate = {learnrate}\n",
    "entcoeff = {entcoeff}\n",
    "batchsize = {batchsize}\n",
    "num_epoch = {num_epoch}\n",
    "\n",
    "# Value Function hyperparameters\n",
    "vf_hidden_size = {vf_hidden_size}\n",
    "seed = {seed}\n",
    "rl_step_size = {rl_step_size}\n",
    "learnrate = {learnrate}\n",
    "entcoeff = {entcoeff}\n",
    "batchsize = {batchsize}\n",
    "num_epoch = {num_epoch}\n",
    "regcoef = {regcoef}\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "# Write data to the file\n",
    "with open(\"myoarmreach#9/readme.txt\", \"w\") as file: #Change the folder name \n",
    "    file.write(data)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myosuite",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
